1.Feign是一个声明式WebService客户端。使用Feign能让编写Web Service客户端更加简单。Feign是对Ribbon的包装，Feign集成了Ribbon。
前面在使用Ribbon+RestTemplate时，利用RestTemplate对http请求的封装处理，形成了一套模版化的调用方法。但是在实际开发中，
由于对服务依赖的调用可能不止一处，往往一个接口会被多处调用，所以通常都会针对每个微服务自行封装一些客户端类来包装这些依赖服务的调用。
所以，Feign在此基础上做了进一步封装，由他来帮助我们定义和实现依赖服务接口的定义。在Feign的实现下，我们只需创建一个接口并使用注解的方式来配置它，
即可完成对服务提供方的接口绑定，简化了使用Spring cloud Ribbon时，自动封装服务调用客户端的开发量。

2.如果一个请求需要调起多个服务时，其中一个服务不通或失败，当大量请求发生时，会导致请求延时和资源浪费。
Hystrix是一个用于处理分布式系统的延迟和容错的开源库，在分布式系统里，许多依赖不可避免的会调用失败，比如超时、
异常等，Hystrix能够保证在一个依赖出问题的情况下，不会导致整体服务失败，避免级联故障，以提高分布式系统的弹性。
当某个服务单元发生故障之后，通过断路器的故障监控，向调用方返回一个符合预期的、可处理的备选响应（FallBack），
而不是长时间的等待或者抛出调用方无法处理的异常，这样就保证了服务调用方的线程不会被长时间、不必要地占用，从而
避免了故障在分布式系统中的蔓延，乃至雪崩。Hystrix可用于服务熔断、服务降级、服务限流等作用。
	2.1、服务熔断
		当某个服务出现异常时，熔断该服务，快速返回指定的错误信息，当服务正常时，恢复熔断。
	2.2、服务降级
		在一个分布式系统中，当访问高峰期或资源有限时，需要关掉某个服务，若有请求访问该服务，
		不能因为系统服务关掉了，就一直中断在该调用服务处，这时就需要请求返回指定的错误信息。
		例如在分布式系统中有A、B两个服务，因为资源有限，需要关掉B服务，A服务在调用B服务时，没有调通
		，此时A返回指定的错误信息，注意不是在B服务端返回的，是A客户端返回的错误信息
	2.33、服务监控
		hystrix除了应用于上述的服务熔断和降级，还可以应用于服务的实时监控。Hystrix会持续地记录所有
		通过Hystrix发起的请求的执行信息，并以统计报表和图形的形式展示给用户，包括每秒执行多少请求多
		少成功，多少失败等。Netflix通过hystrix-metrics-event-stream项目实现了对以上指标的监控。Spring Cloud
		也提供了Hystrix Dashboard的整合，对监控内容转化成可视化界面。
		
3. Zuul路由
	Zuul路由包含了对请求的路由和过滤两个功能。
	路由：路由功能负责将外部请求转发到具体的微服务实例上，是实现外部访问统一入口；
	过滤：过滤器功能则负责对请求的处理过程进行干预，是实现请求校验、服务聚合等功能的基础。
		Zuul和Eureka进行整合，将Zuul自身注册为Eureka服务治理下的应用，同时从Eureka中获得其他微服务的消息，
		也即以后的访问微服务都是通过Zuul跳转后获得。Zuul服务最终也会注册进Eureka。
		
4.Config配置
	一个分布式系统有可能包括非常多微服务，每个微服务都有独自的配置文件，当系统变更时，有可能需要修改很多服务
	的配置文件，导致运维繁琐，容易出问题，所以需要一套集中式的、动态的配置管理设施。spring cloud提供了Config来解决该问题。
	Config的Server端用来连接github，Config的Client端通过Server端去github请求相关的配置信息。
	
	
kafka
	zkServer.cmd .\bin\windows\kafka-server-start.bat .\config\server.properties 删除kafka logs
1. 基于zookeeper协调的分布式消息系统，它的最大特性就是可以实时的处理大量数据以满足各种场景需求
    1.1  Kafka的特性:
        高吞吐量、低延迟：kafka每秒可以处理几十万条消息，它的延迟最低只有几毫秒，每个topic可以分多个partition, consumer group 对partition进行consume操作
        可扩展性：kafka集群支持热扩展
        持久性、可靠性：消息被持久化到本地磁盘，并且支持数据备份防止数据丢失
        容错性：允许集群中节点失败（若副本数量为n,则允许n-1个节点失败）
        高并发：支持数千个客户端同时读写
    1.2   Kafka的使用场景：
        日志收集：一个公司可以用Kafka可以收集各种服务的log，通过kafka以统一接口服务的方式开放给各种consumer，例如hadoop、Hbase、Solr等。
        消息系统：解耦和生产者和消费者、缓存消息等。
        用户活动跟踪：Kafka经常被用来记录web用户或者app用户的各种活动，如浏览网页、搜索、点击等活动，这些活动信息被各个服务器发布到kafka的topic中，然后订阅者通过订阅这些topic来做实时的监控分析，或者装载到hadoop、数据仓库中做离线分析和挖掘。
        运营指标：Kafka也经常用来记录运营监控数据。包括收集各种分布式应用的数据，生产各种操作的集中反馈，比如报警和报告。
        流式处理：比如spark streaming和storm
        事件源

线程池按以下行为执行任务
    1. 当线程数小于核心线程数时，创建线程。
    2. 当线程数大于等于核心线程数，且任务队列未满时，将任务放入任务队列。
    3. 当线程数大于等于核心线程数，且任务队列已满
        - 若线程数小于最大线程数，创建线程
        - 若线程数等于最大线程数，抛出异常，拒绝任务
	1、newCachedThreadPool：用来创建一个可以无限扩大的线程池，适用于负载较轻的场景，执行短期异步任务。（可以使得任务快速得到执行，因为任务时间执行短，可以很快结束，也不会造成cpu过度切换）

	2、newFixedThreadPool：创建一个固定大小的线程池，因为采用无界的阻塞队列，所以实际线程数量永远不会变化，适用于负载较重的场景，对当前线程数量进行限制。（保证线程数可控，不会造成线程过多，导致系统负载更为严重）

	3、newSingleThreadExecutor：创建一个单线程的线程池，适用于需要保证顺序执行各个任务。

	4、newScheduledThreadPool：适用于执行延时或者周期性任务。
	
docker 部署springcloud
	1. 打包eureka.jar 打包 打包服务task.jar 打包zuul.jar将三个微服务打成jar包，并上传到服务器
	2. 编写各自的Dockerfile
	3. 分别将三个jar打成镜像
	4. 接着运行三个镜像并且映射了端口号
	5. 修改三个微服务项目的application.yml配置文件，追加 eureka.instance.prefer-ip-address: true（表示微服务显示IP）
	6. 容器会像虚拟机一样自动被分配了一个虚拟ID，并映射了主机的端口号，这样便可以从外部访问到容器并且能够实现容器间的通讯了

	1、FROM

		指令必须指定且需要在Dockerfile其他指令的前面，指定的基础image可以是官方远程仓库中的，也可以位于本地仓库。后续的指令都依赖于该指令指定的image。当在同一个Dockerfile中建立多个镜像时，可以使用多个FROM指令。
	2、ADD

		从src目录复制文件到容器的dest，可以是一个URL，还可以是一个jar包
	
	3、EXPOSE

		为Docker容器设置对外的端口号。在启动时，可以使用-p选项或者-P选项。
	4、ENTRYPOINT

		该命令制定Docker容器启动时执行的命令，可多次设置，但只有最后一条会生效。
	
	
	
aop： aop 面向切面编程，底层的实现主要是动态代理，而我们在项目中应用比如包括日志记录，事物处理等（前置通知，后置通知，环绕通知，异常通知，返回通知等）
ioc： 如果A类调用B，传统的方法是在A里new 一个B的实例，那么这样的话两者之间就会产生依赖，而引入ioc就是要实例注入到spring容器，并交给spring去管理，降低耦合度
	
spring事物：	分布式事物：如果A系统事务提交成功了，但是B系统在提交的时候网络波动或者各种原因提交失败了，其实还是会失败的
	
	事物的传播行为：当事务方法被另一个事务方法调用时，必须指定事务应该如何传播 例如：方法可能继续在现有事务中运行，也可能开启一个新事务，并在自己的事务中运行
		支持当前事物的情况：
		PROPAGATION_REQUIRED: 如果当前存在事务,则加入该事务;如果当前没有事务,则创建一个新的事务。
		PROPAGATION_SUPPORTS: 如果当前存在事务,则加入该事务;如果当前没有事务,则以非事务的方式继续运行。
		PROPAGATION_MANDATORY: 如果当前存在事务,则加入该事务;如果当前没有事务,则抛出异常。(mandatory:强制性)
		
		不支持当前事务的情况:
TransactionDefinition.PROPAGATION_REQUIRES_NEW: 创建一个新的事务,如果当前存在事务,则把当前事务挂起。
TransactionDefinition.PROPAGATION_NOT_SUPPORTED: 以非事务方式运行,如果当前存在事务,则把当前事务挂起。
TransactionDefinition.PROPAGATION_NEVER: 以非事务方式运行,如果当前存在事务,则抛出异常。

	事物的隔离级别：
		
		
restful :为了方便不同设备前后端交互通信，就需要有一种统一的机制，即RESTful，通过统一的接口为不同设备提供服务;
		对于该URL标识的资源做何种操作是由Http的动词决定的。 rest请求方法有4种，包括get,post,put,delete.分别对应获取资源，
		添加资源，更新资源及删除资源.
		
1.如何处理并发？
	a. 添加负载均衡层，将请求均匀打到系统层。
	b. 系统层采用集群化部署多台机器，抗住初步的并发压力。
	c. 数据库分库分表 + 读写分离
	d. 可以根据系统的业务特性，对那种写少读多的请求，引入缓存集群。
	e. 比如说消息中间件技术，也就是MQ集群，是非常好的做写请求异步化处理，实现削峰填谷的效果。
	
 读写分离，基本的原理是让主数据库处理事务性增、改、删操作（INSERT、UPDATE、DELETE），而从数据库处理SELECT查询操作。数据库复制被用来把事务性操作导致的变更同步到集群中的从数据库。

	复制的工作过程
1） 在每个事务更新数据完成之前，master在二进制日志记录这些改变。写入二进制日志完成后，master通知存储引擎提交事务。

2） Slave将master的binary log复制到其中继日志。首先slave开始一个工作线程（I/O），I/O线程在master上打开一个普通的连接，然后开始binlog dump  process。binlog  dump  process从master的二进制日志中读取事件，如果已经跟上master，它会睡眠并等待master产生新的事件，I/O线程将这些事件写入中继日志。

3） Sql  slave  thread（sql从线程）处理该过程的最后一步，sql线程从中继日志读取事件，并重放其中的事件而更新slave数据，使其与master中的数据一致，只要该线程与I/O线程保持一致，中继日志通常会位于os缓存中，所以中继日志的开销很小。
	配置dataSource为可路由数据源
	1.用户向sso系统发起登录请求 2.系统跳转登录界面 3action接收用户的参数 4后台根据用户名从数据库中查密码 5.如果密码正确，生成一个token(令牌)，
		并将用户的信息保存到redis中，设置过期时间 6返回登录成功的界面 ,将token写入cookie 7用户访问订单系统 ，请求查询订单 8从cookie中取token查询,
		调用sso单点登录系统的服务，根据token查询用户的信息 9 接收token，从redis中查询token的值是否存在或者是否过期，如果有效，直接返回订单信息。